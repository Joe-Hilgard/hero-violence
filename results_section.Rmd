---
title: "Hero Violence"
author: "Joe Hilgard"
date: "June 7, 2017"
output: 
  word_document:
    reference_docx: template_0.docx
---

```{r, echo = F, warning=F, message=F}
library(car)
library(pscl)
library(hilgard)
library(plyr)
library(tidyverse)
library(broom)
library(cowplot)
library(lmtest)
load("./R-objects/analysis.RData")

report_LRchisq <- function(model, effect) {

  frame <- tidy(car::Anova(model, type = 3))
  df <- with(frame, df[term == effect])

  chisq <- with(frame, LR.Chisq[term == effect])
  chisq <- round(chisq, 2)

  p <- with(frame, p.value[term == effect])
  p <- fix_p(p)

  output <- paste0("*chisq*(", df, ") = ", chisq, ", ", p)
  return(output)
}

report_LR <- function(row) {

  df <- row$df

  chisq <- row$LR.chisq
  chisq <- round(chisq, 2)

  p <- row$p.value
  p <- fix_p(p)

  output <- paste0("*chisq*(", df, ") = ", chisq, ", ", p)
  return(output)
}
```

## Sample
An initial data collection included 216 subjects, 191 of which were successfully intercepted by the confederate as they left the laboratory. During data collection, the Spring semester ended before data collection was completed.  We looked at the data to examine whether it was trending in the hypothesized direction, with the idea that we would continue data collection as planned if it was, and would drop data collection if it was not.  The data was indeed trending in the hypothesized direction, so we picked up data collection as originally planned in the following Fall semester.  This natural pause in data collection and evaluation of whether or not to continue collecting data may or may not influence Type I error rates. Additionally, we decided to exclude a semester's worth of participants from one study site (*n* = 31, 21 of which were intercepted), as the confederate used for only that semester did not correctly collect data as was instructed. To support this exclusion of the data, we found the participants solicited by this confederate were statistically less likely to volunteer than other participants, `r report_kt(badgrouptest)`.  This left us with a final sample of 204 subjects, 189 of which were successfully intercepted by the confederate. This left us with a final sample of 204 subjects, 189 of which were successfully intercepted. 

Our primary analyses concern this final sample. However, to explore the robustness of our results, we also analyze the data including those 31 excluded participants.

## Distribution

Initial inspection of the data revealed pronounced non-normality (Figure 1). Many subjects did not offer to make any calls, and among thosewho did, the number of calls offered was strongly right-skewed and favored multiples of 5. 

```{r, echo = F, warning=F, message=F}
dat.4 %>% 
  mutate(Request = factor(Request, 
                          levels=c(1,2), 
                          labels=c("Help Red Cross", "Save Lives"))) %>% 
  ggplot(aes(x = Calls)) +
  geom_histogram() +
  facet_grid(Game ~ Request) +
  theme_bw()
```

This non-normality creates ambiguity in what might be the most appropriate model to fit. Although ANOVA is commonly used and fairly robust to outliers, its assumptions would seem to be violated by the pronounced non-normality of the residuals (see e.g. Glass, Peckham, and Sanders, 1972). 
Therefore, we fit alternative models to explore the robustness of the result and to characterize the analytic ambiguity of the results. In total, we fit:
1) ANOVA
2) logistic regression, testing whether condition affected the odds of volunteering to make any calls
3) a chi-squared test, again testing whether condition affected the odds of volunteering to make any calls
4) a zero-inflated negative binomial, which accounts for the frequent zero-responses and the strong right skew, and
5) a non-parametric Kruskal-Wallis test for differences in the median.
Results for each model are reported separately, then synthesized and summarized at the end.

<!--- In the analyses below, generally use Anova() to look at omnibus effect, 
summary() to look at pairwise comparisons against control,
model.c to look at pairwise anti- vs pro-social contrast--->

### ANOVA
```{r, message = F, echo = F, warning=F, include = F}
Anova(aovmod[[4]], type = 3)
summary(aovmod[[4]])
```
ANOVA indicated a significant effect of game, `r report_f(aovmod[[4]], "Game")`. Neither the effect of request nor the Game × Request interaction was statistically significant, `r report_f(aovmod[[4]], "Request")` and `r report_f(aovmod[[4]], "Game:Request")`, respectively.  

Collapsing across levels of request, a contrast between the prosocial-violence and antisocial-violence conditions was statistically significant, `r report_t(aovmod.c[[4]], "GameProsocial")`. Neither game significantly differed from control. 

### Logistic GLM
To test whether the game influenced the odds of volunteering, we collapsed observations to a binomial outcome (0 = did not volunteer, 1 = volunteered). A logistic GLM was fit to test for effects.

```{r, message = F, echo = F, warning=F, include = F}
Anova(logist[[4]], type = 3)
summary(logist[[4]])
```
The effect of game was not statistically significant, but not especially far from significance either, `r report_LRchisq(logist[[4]], "Game")`. Effects of request and the Game x Request interaction were not statistically significant, `r report_LRchisq(logist[[4]], "Request")` and `r report_LRchisq(logist[[4]], "Game:Request")`, respectively.

```{r, echo = F, warning=F, message = F, include = F}
summary(logist.c[[4]])
```

Again, the contrast between the prosocial-violent and antisocial-violent games was statistically significant, `r report_z(logist.c[[4]], "GameProsocial")`. However, neither game significantly differed from control.

## Chi-squared test
```{r, echo = F, warning=F, message = F, include = F}
chisq[[4]]
chisq.c[[4]]
```
A chi-squared test was used to test whether the probability of volunteering at all differed across game conditions  (collapsing across levels of request). The omnibus test for game type was not significant, but not far from significance, `r report_kt(chisq[[4]])`. As in other analyses, the contrast between prosocial-violent and antisocial-violent was just significant, `r report_kt(chisq.c[[4]])`, although neither game significantly differed from control.

## Zero-inflated negative binomial

A zero-inflated negative binomial was then fit to the data. This model has two parts: The zero-inflation model, which estimates whether participants volunteer at all, and the count model, which estimates how many calls they offer when they do volunteer.

```{r, echo = F, warning=F, message=F, include=F}
Anova(zinbmod[[4]], type = 3)
summary(zinbmod[[4]])

```

Because we did not have reason to expect the game would influence only the zero-inflation model or only the count model, we tested the overall effect of game on both parameters simultaneously with likelihood-ratio chi-square tests. The effect of game was ambiguous, neither statistically significant nor particularly far from significance (`r filter(zinbmod.result, dataset == 4, term == "Game") %>% report_LR()`). Effects of request (`r filter(zinbmod.result, dataset == 4, term == "Request") %>% report_LR()`) or the Game × Request interaction (`r filter(zinbmod.result, dataset == 4, term == "Game:Request") %>% report_LR()`) were not significant. The overdispersion parameter was highly significant (*z* = 4.61, *p* < .001), supporting the use of the negative binomial over a zero-inflated Poisson distribution.

```{r, echo = F, warning=F, message = F, include = F}
filter(zinb.c.result, dataset == 4)
filter(zinb.zero.c.result, dataset == 4)
filter(zinb.count.c.result, dataset == 4)
```

<!--- Putting these in by hand from table above--->
A pairwise contrast between the prosocial-violent and antisocial-violent games yielded a significant effect of game, *chisq*(2) = 6.67, *p* = .036. Tests of individual parameters found a significant difference on the zero-inflation parameter (*z* = -2.17, *p* = .030) but not on the count parameter (*z* = 1.30, *p* = .193). Again, neither game differed from control.

## Kruskal-Wallis test
The Kruskal-Wallis test is a nonparametric test of group medians. Because the test is only applicable to one-way ANOVA designs and the primary hypothesis regarded effects of game, we collapsed across levels of request and tested for an effect of game. As in other analyses, the omnibus effect of game was not statistically significant, but not far from significance, *chisq*(2) = 5.09, *p* = .079.

```{r, echo = F, warning=F, message=F, include=F}
(kruskal[[4]])
```



```{r, echo = F, warning=F, message=F, include=F}
(kruskal.c[[4]])
kruskal.test(Calls ~ Game, data = dat.4, subset = Game %in% c("Antisocial", "Control"))
kruskal.test(Calls ~ Game, data = dat.4, subset = Game %in% c("Control", "Prosocial"))
```

The pairwise contrast between the antisocial and prosocial violent games was statistically significant, *chisq*(1) = 4.97, *p* = .026. However, neither game significantly differed from control, *p* = .224, .262.

# Describing uncertainty
## Uncertainty across models
Figure 2A shows the distribution of omnibus test *p*-values across the five models. Figure 2B shows the distribution of pairwise prosocial/antisocial game contrast *p*-values across the five models. 

```{r, echo = F, message=F, warning=F}
omnibus.p <- filter(omnibus.results, dataset == 4, term == "Game")
contrast.p <- filter(contrast.results, dataset == 4, 
                     term %in% c("Game", "GameProsocial")) 

pplot <- function(x, title) {
  PLOT <- x %>% 
    arrange(p.value) %>% 
    mutate(., row = 1:nrow(.),
           sig = p.value < .05) %>% 
    ggplot(aes(x = row, y = p.value, shape = sig
               #, col = dataset
               )) +
    scale_shape_identity(aes(solid = sig)) +
    geom_point(size = 3) +
    theme_bw() +
    scale_y_continuous(limits = c(0, .25)) +
    geom_hline(yintercept = .05) +
    geom_hline(yintercept = .1, lty = 2) +
    ggtitle(title) +
    #scale_color_grey(start = .2, end = .5) +
    theme(axis.title.x = element_blank(),
          axis.text.x = element_blank(),
          axis.ticks.x = element_blank()) + 
    guides(col = F)
}

f2a <- pplot(omnibus.p, "Omnibus test results")
f2b <- pplot(contrast.p, "Contrast test results") 
plot_grid(f2a, f2b, labels = c("A", "B"), ncol = 2)
```

Across models, the omnibus test is generally not statistically significant (median *p* = `r round(median(omnibus.p$p.value), 3)`), reaching a minimum p-value of `r round(min(omnibus.p$p.value), 3)` in the ANOVA model. The pairwise contrast, on the other hand, is generally statistically significant. Its *p*-values range from .015 (ANOVA) to .044 (chi-squared test), with median *p* = `r round(median(contrast.p$p.value), 3)`. 

## Uncertainty across datasets
In the analyses presented above, 31 participants were excluded after it was found that the confederate at one site during one semester was not collecting data as instructed.
One may wonder how robust the results are to the inclusion of these subjects. Figure 3 shows the variability in the *p*-value across this decision to include or exclude. Six parameters in two datasets yields twelve *p*-values. Figure 3A shows the distribution of omnibus test *p*-values, and Figure 3B shows the distribution of pairwise contrast *p*-values across the five models. 

```{r, echo = F, message=F, warning=F}
omnibus.p.14 <- filter(omnibus.results, 
              term == "Game", 
              dataset %in% c(1, 4))
contrast.p.14 <- filter(contrast.results, 
              term %in% c("Game", "GameProsocial"),
              dataset %in% c(1,4))

f3a <- pplot(omnibus.p.14, "Omnibus test results")
f3b <- pplot(contrast.p.14, "Contrast test results")
plot_grid(f3a, f3b, labels = c("A", "B"), ncol = 2)
```

Together, these figures illustrate the uncertainty in the *p*-value across datasets. Again, we note that only one analysis yielded a significant omnibus test. Additionally, some of the pairwise contrasts are no longer statistically significant when including the 31 subjects of questionable quality. 
Naturally, bad data should be excluded. Still, to the extent that this decision was made *ad hoc*, it is useful to note their influence on the *p*-value.

# Bayesian ANOVA
One last way to consider the results would be through a Bayesian ANOVA. Like the frequentist ANOVA presented above, this model suffers from violated assumptions of normally distributed residuals. However, it does have the advantage of appraising the evidence in terms of continuous odds rather than the dichotomy of statistical significance. Effects were tested using the anovaBF() function in the BayesFactor package (Morey & Rouder, 2015) using a Cauchy prior with scale parameter 0.4, consistent with effects typical of social psychology.

These ANOVAs indicated ambiguous evidence regarding an omnibus effect of game, 1.15:1 odds in favor of H1 over H0. Odds in favor of the prosocial/antisocial game contrast were stronger, but still marginal at 2.96:1 in favor of H1 over H0.
When including the 31 subjects of questionable quality, these ANOVAs indicated 1.94:1 odds against an omnibus effect of game and 1.44:1 odds in favor of a prosocial/antisocial game contrast. 
This Bayesian approach indicates that the results are ambiguous and that neither H1 nor H0 is a clear winner, consistent with the other analyses presented above. 

# Discussion
We generally did not detect a significant overall effect of game on prosocial behavior. Still, pairwise contrasts suggested a significant difference in behavior following the prosocial-violent as compared to the antisocial-violent game. However, this contrast should be interpreted with caution given that neither violent game significantly differed from the control game. Evidence was generally equivocal, as indicated by the Bayesian ANOVA.

Considerable uncertainty remains. The decision to exclude subjects is justifiable, but not based on any *a priori* rule, creating another researcher degree of freedom. The prosocial-violence vs. antisocial-violence contrast is one of three potential contrasts that consider the effects of game. Finally, the results are a little sensitive to the particular model applied. Whereas a typical manuscript might conceal the ambiguity by presenting just one analysis, here we find it most helpful to show all possible analyses.

This uncertainty should not be mistaken for an argument that games do not influence prosocial behavior. Although statistical significance is sporadic and sensitive to choice of model, contrast, or inclusion rules, it is generally not the case that the results constitute clear support for the null hypothesis.

The results of this study are nonetheless helpful in estimating the effects of antisocial-violent and prosocial-violent games. It is unclear whether these types of games differ from control games in their effects on prosocial behavior. If such effects exist, they are likely not large and obvious, at least using this particular measure. Furthermore, we are able to rule out some effects of the opposite direction. The data are inconsistent with antisocial-violent games *promoting* prosocial behavior or prosocial-violent games *inhibiting* prosocial behavior.

The prosocial measure used in the current study was a considerable limitation. Several of the participants that completed the lab portion of the study were missed by the confederate, so they were unable to encounter the prosocial portion of the experiment.  Additionally most participants declined to volunteer, causing something of a floor effect.  A prosocial measure in which most participants are willing to help at least a little bit would be more sensitive.  This would also be more effective in testing potential decreases in prosocial behavior, as the control group mean would be further from the floor. Better psychometric properties would also provide a better test of potential increases in prosocial behavior following a violent-prosocial game. 

In conclusion, despite collection of a moderately-sized sample, the results are ambiguous regarding whether prosocial-violent and antisocial-violent games affect prosocial behavior as compared to a nonviolent game. Some support for a difference between antisocial and prosocial violent games was found, but this difference was sensitive to the choice of model and dataset. Future research is encouraged to test the effects of prosocial, antisocial, violent, and nonviolent games on prosocial behavior. This research program would be facilitated by the development of more sensitive and model-friendly measures of prosocial behavior.

In particular, with a better measure of prosocial behavior, the current ambiguous results that provide some very tentative support for the difference between prosocial-violent and antisocial-violent could be clarified.  It is possible that violent video games reduce prosocial behavior, whereas the prosocial element of violent video games may counteract the violent nature of the game, which would result in similar prosocial behavior to a control game.  On the other hand, it is possible that the prosocial element of a violent video game increases prosocial behavior above an antisocial violent game, which may or may not be different from a control game.  Another possibility is that a prosocial violent video game encourages both prosocial behavior and aggression, but the context determines which of those responses would be elicited.  For instance, after playing a prosocial violent game, the prosocial element of the game may influence players to help an elderly person across the street, while the violent element of the game may influence the player to yell at someone in a car that impatiently honks at the delay.  Future research should work to disentangle all of these possibilities and further enhance our understanding of the potential different effects that antisocial violence and prosocial violence may have on the gamer.